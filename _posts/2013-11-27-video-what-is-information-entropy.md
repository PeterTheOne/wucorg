---
layout: post
title: Video - What is Information Entropy?
description: Video - What is Information Entropy?
author: Melvin Draupnir
authorurl: /melvin-draupnir/
published: true
---

<p>Entropy is a measure of the uncertainty in a random variable (message source). Claude Shannon defines the "bit" as the unit of entropy (which is the uncertainty of a fair coin flip). In this video information entropy is introduced intuitively using bounce machines & yes/no questions. </p>

<center><iframe width="700" height="394" src="https://www.youtube.com/embed/R4OlXb9aTvQ?list=PLbg3ZX2pWlgKDVFNwn9B63UhYJVIerzHL" frameborder="0" allowfullscreen></iframe></center>

<h2>TRANSCRIPT</h2>
